
# Machine Translation Paper List (Non-Autoregressive Translation)
<table>
<tr>
    <td>Paper</td>
    <td>Autors</td>
    <td>Venue</td>
    <td>Link</td>
</tr>
<tr>
	<td>Non-Autoregressive Neural Machine Translation</td>
	<td>*Jiatao Gu, James Bradbury, Caiming Xiong, Victor O. K. Li, Richard Socher*</td>
	<td>ICLR-2018</td>
	<td>https://arxiv.org/abs/1711.02281</td>
</tr>
<tr>
	<td>Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement</td>
	<td>*Jason Lee, Elman Mansimov, Kyunghyun Cho*</td>
	<td>EMNLP-2018</td>
	<td>https://doi.org/10.18653/v1/d18-1149</td>
</tr>
<tr>
	<td>Fast Decoding in Sequence Models Using Discrete Latent Variables</td>
	<td>*Lukasz Kaiser, Samy Bengio, Aurko Roy, Ashish Vaswani, Niki Parmar, Jakob Uszkoreit, Noam Shazeer*</td>
	<td>ICML-2018</td>
	<td>https://arxiv.org/pdf/1803.03382.pdf</td>
</tr>
<tr>
	<td>Imitation Learning for Non-Autoregressive Neural Machine Translation</td>
	<td>*Bingzhen Wei, Mingxuan Wang, Hao Zhou, Junyang Lin, Xu Sun*</td>
	<td>ACL-2019</td>
	<td>https://doi.org/10.18653/v1/p19-1125</td>
</tr>
<tr>
	<td>Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation</td>
	<td>*Chenze Shao, Yang Feng, Jinchao Zhang, Fandong Meng, Xilin Chen, Jie Zhou*</td>
	<td>ACL-2019</td>
	<td>https://doi.org/10.18653/v1/p19-1288</td>
</tr>
<tr>
	<td>Syntactically Supervised Transformers for Faster Neural Machine Translation</td>
	<td>*Nader Akoury, Kalpesh Krishna, Mohit Iyyer*</td>
	<td>ACL-2019</td>
	<td>https://doi.org/10.18653/v1/p19-1122</td>
</tr>
<tr>
	<td>Non-Autoregressive Machine Translation with Auxiliary Regularization</td>
	<td>*Yiren Wang, Fei Tian, Di He, Tao Qin, ChengXiang Zhai, Tie-Yan Liu*</td>
	<td>AAAI-2019</td>
	<td>https://doi.org/10.1609/aaai.v33i01.33015377</td>
</tr>
<tr>
	<td>Non-Autoregressive Neural Machine Translation with Enhanced Decoder Input</td>
	<td>*Junliang Guo, Xu Tan, Di He, Tao Qin, Linli Xu, Tie-Yan Liu*</td>
	<td>AAAI-2019</td>
	<td>https://doi.org/10.1609/aaai.v33i01.33013723</td>
</tr>
<tr>
	<td>Mask-Predict: Parallel Decoding of Conditional Masked Language Models</td>
	<td>*Marjan Ghazvininejad, Omer Levy, Yinhan Liu, Luke Zettlemoyer*</td>
	<td>EMNLP-2019</td>
	<td>https://doi.org/10.18653/v1/D19-1633</td>
</tr>
<tr>
	<td>Insertion-based Decoding with Automatically Inferred Generation Order</td>
	<td>*Jiatao Gu, Qi Liu, Kyunghyun Cho*</td>
	<td>TACL-2019</td>
	<td>https://transacl.org/ojs/index.php/tacl/article/view/1732</td>
</tr>
<tr>
	<td>Fast Structured Decoding for Sequence Models</td>
	<td>*Zhiqing Sun, Zhuohan Li, Haoqing Wang, Di He, Zi Lin, Zhi-Hong Deng*</td>
	<td>NeurIPS-2019</td>
	<td>http://papers.nips.cc/paper/8566-fast-structured-decoding-for-sequence-models</td>
</tr>
<tr>
	<td>Levenshtein Transformer</td>
	<td>*Jiatao Gu, Changhan Wang, Junbo Zhao*</td>
	<td>NeurIPS-2019</td>
	<td>https://papers.nips.cc/paper/9297-levenshtein-transformer</td>
</tr>
<tr>
	<td>Hint-Based Training for Non-Autoregressive Machine Translation</td>
	<td>*Zhuohan Li, Zi Lin, Di He, Fei Tian, Tao Qin, Liwei Wang, Tie-Yan Liu*</td>
	<td>EMNLP-2019</td>
	<td>https://doi.org/10.18653/v1/D19-1573</td>
</tr>
<tr>
	<td>FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow</td>
	<td>*Xuezhe Ma, Chunting Zhou, Xian Li, Graham Neubig, Eduard H. Hovy*</td>
	<td>EMNLP-2019</td>
	<td>https://doi.org/10.18653/v1/D19-1437</td>
</tr>
<tr>
	<td>Improving Non-autoregressive Neural Machine Translation with Monolingual Data</td>
	<td>*Jiawei Zhou, Phillip Keung*</td>
	<td>ACL-2020</td>
	<td>https://www.aclweb.org/anthology/2020.acl-main.171</td>
</tr>
<tr>
	<td>Parallel Machine Translation with Disentangled Context Transformer</td>
	<td>*Jungo Kasai, James Cross, Marjan Ghazvininejad, Jiatao Gu*</td>
	<td>ICML-2020</td>
	<td>https://arxiv.org/abs/2001.05136</td>
</tr>
<tr>
	<td>Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation</td>
	<td>*Junliang Guo, Linli Xu, Enhong Chen*</td>
	<td>ACL-2020</td>
	<td>https://www.aclweb.org/anthology/2020.acl-main.36</td>
</tr>
<tr>
	<td>A Study of Non-autoregressive Model for Sequence Generation</td>
	<td>*Yi Ren, Jinglin Liu, Xu Tan, Zhou Zhao, Sheng Zhao, Tie-Yan Liu*</td>
	<td>ACL-2020</td>
	<td>https://www.aclweb.org/anthology/2020.acl-main.15</td>
</tr>
<tr>
	<td>Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation</td>
	<td>*Qiu Ran, Yankai Lin, Peng Li, Jie Zhou*</td>
	<td>ACL-2020</td>
	<td>https://www.aclweb.org/anthology/2020.acl-main.277</td>
</tr>
<tr>
	<td>ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</td>
	<td>*Lifu Tu, Richard Yuanzhe Pang, Sam Wiseman, Kevin Gimpel*</td>
	<td>ACL-2020</td>
	<td>https://www.aclweb.org/anthology/2020.acl-main.251</td>
</tr>
<tr>
	<td>Latent-Variable Non-Autoregressive Neural Machine Translation with Deterministic Inference Using a Delta Posterior</td>
	<td>*Raphael Shu, Jason Lee, Hideki Nakayama, Kyunghyun Cho*</td>
	<td>AAAI-2020</td>
	<td>https://aaai.org/ojs/index.php/AAAI/article/view/6413</td>
</tr>
<tr>
	<td>Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation</td>
	<td>*Chenze Shao, Jinchao Zhang, Yang Feng, Fandong Meng and Jie Zhou*</td>
	<td>AAAI-2020</td>
	<td>https://aaai.org/ojs/index.php/AAAI/article/view/5351</td>
</tr>
<tr>
	<td>Understanding Knowledge Distillation in Non-autoregressive Machine Translation</td>
	<td>*Chunting Zhou, Jiatao Gu, Graham Neubig*</td>
	<td>ICLR-2020</td>
	<td>https://openreview.net/forum?id=BygFVAEKDH</td>
</tr>
<tr>
	<td>Aligned Cross Entropy for Non-Autoregressive Machine Translation</td>
	<td>*Marjan Ghazvininejad, Vladimir Karpukhin, Luke Zettlemoyer, Omer Levy*</td>
	<td>ICML-2020</td>
	<td>https://doi.org/10.18653/v1/p19-1122</td>
</tr>
<tr>
	<td>Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation</td>
	<td>*Junliang Guo, Xu Tan, Linli Xu, Tao Qin, Enhong Chen, Tie-Yan Liu*</td>
	<td>AAAI-2020</td>
	<td>https://aaai.org/ojs/index.php/AAAI/article/view/6289</td>
</tr>
<tr>
	<td>Non-Autoregressive Machine Translation with Latent Alignments</td>
	<td>*Chitwan Saharia, William Chan, Saurabh Saxena, Mohammad Norouzi*</td>
	<td>CoRR</td>
	<td>https://arxiv.org/abs/2004.07437</td>
</tr>
<tr>
	<td>Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information</td>
	<td>*Qiu Ran, Yankai Lin, Peng Li, Jie Zhou*</td>
	<td>CoRR</td>
	<td>http://arxiv.org/abs/1911.02215</td>
</tr>
<tr>
	<td>LAVA NAT: A Non-Autoregressive Translation Model with Look-Around Decoding and Vocabulary Attention</td>
	<td>*Xiaoya Li, Yuxian Meng, Arianna Yuan, Fei Wu, Jiwei Li*</td>
	<td>CoRR</td>
	<td>https://arxiv.org/abs/2002.03084</td>
</tr>

</table>
